{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Bengali OCR.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamajit-engg/ML/blob/main/Bengali_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "id": "iqdSvTJbG6IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (40, 40, 3)))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Dense(units = 50, activation = 'softmax'))\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV7kQ3caHFp1",
        "outputId": "c3ca71bf-fbe4-4940-999c-3a693e0120a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image, ImageFile\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "z5hyz4v_HLLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "zip_path = '/content/drive/MyDrive/Training dataset /Dataset.zip'  # Replace with the correct path to your .zip file\n",
        "extract_to = '/content/drive/MyDrive/Training dataset '  # Desired extraction path\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# Confirm extraction and list files\n",
        "print(f\"Dataset extracted to: {extract_to}\")\n",
        "print(\"Extracted files:\", os.listdir(extract_to))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0yd-L6US-Kt",
        "outputId": "49f57900-2741-48d0-abaa-840bbedfc238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset extracted to: /content/drive/MyDrive/Training dataset \n",
            "Extracted files: ['Dataset.zip', 'Dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XwhDmLL4YwGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageFile\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = .2, rotation_range = 25)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Training dataset', target_size = (40, 40),\n",
        "                                                 batch_size = 32, class_mode = 'categorical')\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Training dataset', target_size = (40, 40),\n",
        "                                                 batch_size = 32, class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "cqp1WZJxULrG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ef53669f-be22-4d38-f6b0-626e99b5af68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ImageDataGenerator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-aa9361402aec>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshear_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "r85_B85ehAzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "id": "Kh-H5loGHd4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_json = classifier.to_json()\n",
        "\n",
        "with open(\"CNN_BanglaHandWrittenCharacterRecognition.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "\n",
        "classifier.save_weights(\"CNN_BanglaHandWrittenCharacterRecognition.h5\")\n",
        "print('Saved model to disk')"
      ],
      "metadata": {
        "id": "NZjHvohdHkP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import ImageTk, ImageDraw, Image\n",
        "from tkinter import *\n",
        "from keras.preprocessing import image\n",
        "import os"
      ],
      "metadata": {
        "id": "w3Gi_XO8HlT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_new_image():\n",
        "    width = 256\n",
        "    height = 256\n",
        "    center = height // 2\n",
        "    white = (255, 255, 255)\n",
        "    green = (0, 128, 0)\n",
        "\n",
        "    def save():\n",
        "        filename = 'C:/Users/MHB/Desktop/BHWCC/Dataset/SinglePrediction/image.jpg'\n",
        "        image.save(filename)\n",
        "\n",
        "    def paint(event):\n",
        "        x1, y1 = (event.x - 1), (event.y - 1)\n",
        "        x2, y2 = (event.x + 1), (event.y + 1)\n",
        "        cv.create_oval(x1, y1, x2, y2, fill = 'black', width = 30)\n",
        "        draw.line([x1, y1, x2, y2], fill = 'black', width = 30)\n",
        "\n",
        "    root = Tk()\n",
        "\n",
        "    cv = Canvas(root, width = width, height = height, bg = 'white')\n",
        "    cv.pack()\n",
        "\n",
        "    image = PIL.Image.new('RGB', (width, height), white)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    cv.pack(expand = YES, fill = BOTH)\n",
        "    cv.bind(\"<B1-Motion>\", paint)\n",
        "\n",
        "    button = Button(text = 'Save', command = save)\n",
        "    button.pack()\n",
        "\n",
        "    root.mainloop()"
      ],
      "metadata": {
        "id": "NptEN7AaHsw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_character(res):\n",
        "    if res == 0:\n",
        "        print('prediction : অ')\n",
        "    elif res == 1:\n",
        "        print('prediction : আ')\n",
        "    elif res == 2:\n",
        "        print('prediction : ই')\n",
        "    elif res == 3:\n",
        "        print('prediction : ঈ')\n",
        "    elif res == 4:\n",
        "        print('prediction : উ')\n",
        "    elif res == 5:\n",
        "        print('prediction : ঊ')\n",
        "    elif res == 6:\n",
        "        print('prediction : ঋ')\n",
        "    elif res == 7:\n",
        "        print('prediction : এ')\n",
        "    elif res == 8:\n",
        "        print('prediction : ঐ')\n",
        "    elif res == 9:\n",
        "        print('prediction : ও')\n",
        "    elif res == 10:\n",
        "        print('prediction : ঔ')\n",
        "    elif res == 11:\n",
        "        print('prediction : ক')\n",
        "    elif res == 12:\n",
        "        print('prediction : খ')\n",
        "    elif res == 13:\n",
        "        print('prediction : গ')\n",
        "    elif res == 14:\n",
        "        print('prediction : ঘ')\n",
        "    elif res == 15:\n",
        "        print('prediction : ঙ')\n",
        "    elif res == 16:\n",
        "        print('prediction : চ')\n",
        "    elif res == 17:\n",
        "        print('prediction : ছ')\n",
        "    elif res == 18:\n",
        "        print('prediction : জ')\n",
        "    elif res == 19:\n",
        "        print('prediction : ঝ')\n",
        "    elif res == 20:\n",
        "        print('prediction : ঞ')\n",
        "    elif res == 21:\n",
        "        print('prediction : ট')\n",
        "    elif res == 22:\n",
        "        print('prediction : ঠ')\n",
        "    elif res == 23:\n",
        "        print('prediction : ড')\n",
        "    elif res == 24:\n",
        "        print('prediction : ঢ')\n",
        "    elif res == 25:\n",
        "        print('prediction : ণ')\n",
        "    elif res == 26:\n",
        "        print('prediction : ত')\n",
        "    elif res == 27:\n",
        "        print('prediction : থ')\n",
        "    elif res == 28:\n",
        "        print('prediction : দ')\n",
        "    elif res == 29:\n",
        "        print('prediction : ধ')\n",
        "    elif res == 30:\n",
        "        print('prediction : ন')\n",
        "    elif res == 31:\n",
        "        print('prediction : প')\n",
        "    elif res == 32:\n",
        "        print('prediction : ফ')\n",
        "    elif res == 33:\n",
        "        print('prediction : ব')\n",
        "    elif res == 34:\n",
        "        print('prediction : ভ')\n",
        "    elif res == 35:\n",
        "        print('prediction : ম')\n",
        "    elif res == 36:\n",
        "        print('prediction : য')\n",
        "    elif res == 37:\n",
        "        print('prediction : র')\n",
        "    elif res == 38:\n",
        "        print('prediction : ল')\n",
        "    elif res == 39:\n",
        "        print('prediction : শ')\n",
        "    elif res == 40:\n",
        "        print('prediction : ষ')\n",
        "    elif res == 41:\n",
        "        print('prediction : স')\n",
        "    elif res == 42:\n",
        "        print('prediction : হ')\n",
        "    elif res == 43:\n",
        "        print('prediction : ড়')\n",
        "    elif res == 44:\n",
        "        print('prediction : ঢ়')\n",
        "    elif res == 45:\n",
        "        print('prediction : য়')\n",
        "    elif res == 46:\n",
        "        print('prediction : ৎ')\n",
        "    elif res == 47:\n",
        "        print('prediction : ং')\n",
        "    elif res == 48:\n",
        "        print('prediction : ঃ')\n",
        "    else:\n",
        "        print('prediction : ঁ')"
      ],
      "metadata": {
        "id": "jbvdKL3XHt1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def single_prediction(test_img):\n",
        "    test_img_arr = image.img_to_array(test_img)\n",
        "    test_img_arr = np.expand_dims(test_img_arr, axis = 0)\n",
        "    prediction = classifier.predict(test_img_arr)\n",
        "    result = np.argmax(prediction, axis = 1)\n",
        "    determine_character(result)"
      ],
      "metadata": {
        "id": "rTcDnaZSH0Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_created_image():\n",
        "    os.remove('C:/Users/MHB/Desktop/BHWCC/Dataset/SinglePrediction/image.jpg')"
      ],
      "metadata": {
        "id": "EB5H1mb2H4lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def draw_n_guess_the_character():\n",
        "    create_new_image()\n",
        "    test_img = image.load_img('C:/Users/MHB/Desktop/BHWCC/Dataset/SinglePrediction/image.jpg', target_size = (40, 40, 3))\n",
        "    single_prediction(test_img)\n",
        "    plt.imshow(test_img)\n",
        "    delete_created_image()"
      ],
      "metadata": {
        "id": "V5fFnAkVH8WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_n_guess_the_character()"
      ],
      "metadata": {
        "id": "CDr-QTbwH9PX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}